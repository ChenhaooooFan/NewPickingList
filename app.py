import streamlit as st
import pandas as pd
import re
import fitz
from collections import defaultdict

st.set_page_config(page_title="æ‹£è´§å•æ±‡æ€»å·¥å…·", layout="centered")
st.title("ğŸ“¦ NailVesta æ‹£è´§å•æ±‡æ€»å·¥å…·")
st.caption("æå– Seller SKU + æ•°é‡ï¼Œå¹¶æ ¹æ® SKU å‰ç¼€æ˜ å°„äº§å“åç§°ï¼ˆbundle å±•å¼€ç»Ÿè®¡ + å¯¹è´¦å£å¾„åˆ†å¼€ï¼‰")

uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šä¼ æ‹£è´§ PDF", type=["pdf"])

# ========= æ˜ å°„ï¼šSKU å‰ç¼€ â†’ äº§å“åï¼ˆä¿æŒä½ ä¹‹å‰çš„æ•°æ®ï¼‰ =========
sku_prefix_to_name = {
    "NDF001":"Tropic Paradise","NPX014":"Afterglow","NDX001":"Pinky Promise","NHF001":"Gothic Moon","NHX001":"Emerald Garden",
    "NLF001":"Divine Emblem","NLF002":"Athena's Glow","NLJ001":"Golden Pearl","NLJ002":"BAROQUE BLISS","NLJ003":"Rainbow Reef",
    "NLX001":"Mermaid's Whisper","NLX003":"Tropical Tide","NLX005":"Pure Grace","NOF001":"Royal Amber","NOF002":"Tiger Lily",
    "NOF003":"Peach Pop","NOF004":"Sunset Punch","NOF005":"Glacier Petal","NOJ001":"Island Bloom","NOJ002":"Floral Lemonade",
    "NOJ003":"Aurora Tide","NOX001":"Lava Latte","NPD001":"Leopard's Kiss","NPF001":"Angel's Grace","NPF002":"Sacred Radiance",
    "NPF003":"Golden Ivy","NPF005":"Auric Taurus","NPF006":"Cocoa Blossom","NPF007":"Bluebell Glow","NPF008":"Lavender Angel",
    "NPF009":"Vintage Bloom","NPF010":"Pastel Meadow","NPF011":"Cherry Cheetah","NPF012":"Rosey Tigress","NPJ001":"SCARLET QUEEN",
    "NPJ003":"Stellar Capricorn","NPJ004":"Midnight Violet","NPJ005":"Vintage Cherry","NPJ006":"Savanna Bloom","NPJ007":"Angel's Blush",
    "NPJ008":"Gothic Sky","NPJ009":"Violet Seashell","NPX001":"Royal Elegance","NPX002":"Angel's Ruby","NPX005":"Indigo Breeze",
    "NPX006":"Autumn Petal","NPX007":"Lavender Bliss","NPX008":"Dreamy Ballerina","NPX009":"Rose Eden","NPX010":"Blooming Meadow",
    "NPX011":"Safari Petal","NPX012":"Milky Ribbon","NPX013":"Champagne Wishes","NLX004":"Holiday Bunny","NPJ010":"Glossy Doll",
    "NPF013":"Opal Glaze","NOX002":"Cherry Kiss","NOJ004":"Peachy Coast","NYJ001":"Rosy Ribbon","NOF008":"Starlit Jungle",
    "NOF006":"Coral Sea","NOF009":"RosÃ© Angel","NPF014":"Arabian Nights","NOX003":"Caramel Nova","NPF016":"Golden Muse",
    "NPF017":"Ruby Bloom","NOF007":"Citrus Blush","NOJ005":"Ocean Whisper","NPF015":"RosÃ© Petal","NOF010":"Spring Moss",
    "NM001":"Mystery Set","NOF011":"Velvet Flame","NPJ011":"Bat Boo","NOX004":"Azure Muse","NPX016":"Silky Pearl",
    "NPX015":"Spooky Clown","NOX005":"Honey Daisy","NPJ012":"Gothic Mirage","NOX006":"Imperial Bloom","NPX017":"Rouge Letter",
    "NOF013":"Sakura Blush","NPF018":"Wild Berry","NOF012":"Rose Nocturne","NIX001":"Golden Maple","NOX007":"Stellar Whisper",
    "NOF014":"Desert Rose","NPF019":"Lunar Whisper","NOF015":"Mocha Grace","NOX009":"Moonlit Petal","NOX008":"Espresso Petals",
    "NPX018":"Ruby Ribbon"
}
updated_mapping = dict(sku_prefix_to_name)

# ========= å°å·¥å…· =========
ALNUM_HYPHEN = re.compile(r'[A-Z0-9-]+$')                   # åªä¿ç•™å¤§å†™/æ•°å­—/è¿å­—ç¬¦çš„ token
SKU_FULL      = re.compile(r'(?:[A-Z]{3}\d{3}){1,4}-[A-Z]') # 1â€“4 ä»¶ bundle å½¢æ€
QTY_NUM       = re.compile(r'^\d{1,3}$')                    # 1â€“3 ä½æ•°é‡
ORDER_ID      = re.compile(r'^\d{9,}$')                     # â‰¥9 ä½è®¢å•å·

def _clean(t: str) -> str:
    return (t.replace('\u00ad','').replace('\u200b','').replace('\u00a0',' ')
              .replace('â€“','-').replace('â€”','-'))

def expand_bundle(counter: dict, sku_with_size: str, qty: int):
    """å°† 1â€“4 ä»¶ bundle æ‹†åˆ†ä¸ºç‹¬ç«‹ SKUï¼ˆæŒ‰ 6 ä½åˆ‡ç‰‡ï¼‰ã€‚"""
    s = re.sub(r'\s+','', sku_with_size).replace('â€“','-').replace('â€”','-')
    if '-' not in s:
        counter[s] += qty; return
    code, size = s.split('-', 1)
    if len(code) % 6 == 0 and 6 <= len(code) <= 24:
        parts = [code[i:i+6] for i in range(0, len(code), 6)]
        if all(re.fullmatch(r'[A-Z]{3}\d{3}', p or '') for p in parts):
            for p in parts:
                counter[f'{p}-{size}'] += qty
            return
    # å›é€€ï¼šä¸æ»¡è¶³è§„åˆ™åˆ™æŒ‰åŸæ ·è®¡
    counter[s] += qty

# ====== è·¯å¾„1ï¼šè¡¨å¤´è§£æï¼ˆæ¯é¡µåªè·‘ä¸€æ¬¡ï¼›åŒé¡µå»é‡ï¼‰ ======
def parse_by_headers(doc):
    expanded = defaultdict(int)
    raw_total = 0
    pages_with_header = set()

    for pi, page in enumerate(doc):
        words = [(x0,y0,x1,y1,_clean(t)) for (x0,y0,x1,y1,t,_,_,_) in page.get_text('words')]
        if not words:
            continue

        heights = [y1-y0 for _,y0,_,y1,_ in words]
        line_h  = (sum(heights)/len(heights)) if heights else 12
        band    = line_h * 3.0  # å®¹å·®æ”¾å®½ï¼šå¯è¦†ç›–å•å…ƒæ ¼å†…æ¢è¡Œ

        header_words = { re.sub(r'[^a-z]','', t.lower()): x0 for x0,_,_,_,t in words if t and t.isprintable() }

        def get_x(*keys):
            xs = [header_words[k] for k in keys if k in header_words]
            return min(xs) if xs else None

        x_sku = get_x('sellersku','sku','seller')
        x_qty = get_x('qty','quantity')
        x_ord = get_x('orderid','order')

        if x_sku is None or x_qty is None:
            continue

        pages_with_header.add(pi)

        page_w = page.rect.width
        def col_range(left, nxt):
            left = left - 4
            right = (min([n for n in nxt if n is not None]) - 4) if any(nxt) else page_w
            return left, right

        sku_l, sku_r = col_range(x_sku, [x_qty, x_ord])
        qty_l, qty_r = col_range(x_qty, [x_ord])

        # æœ¬é¡µå»é‡ï¼šåŒä¸€è¡Œè¢«å¤šæ¬¡æ¸²æŸ“ï¼ˆæˆ– Qty å‡ºç°ä¸¤ä¸ªçŸ­æ•°å­—ï¼‰åªè®¡ä¸€æ¬¡
        seen = set()

        qtys = []
        for x0,y0,x1,y1,t in words:
            if qty_l <= x0 <= qty_r and QTY_NUM.match(t.strip()):
                qtys.append((x0,y0,x1,y1,int(t.strip())))
        if not qtys:
            continue

        for qx0,qy0,qx1,qy1,qty in qtys:
            yc = (qy0+qy1)/2
            tokens=[]
            for sx0,sy0,_,sy1,t in words:
                if sku_l <= sx0 <= sku_r and abs(((sy0+sy1)/2)-yc) <= band and ALNUM_HYPHEN.match(t):
                    tokens.append((sy0, sx0, t))
            if not tokens:
                continue

            tokens.sort(key=lambda k: (round(k[0],1), k[1]))
            cat = re.sub(r'\s+','', ''.join(t for _,_,t in tokens))
            m = SKU_FULL.search(cat)
            if not m:
                continue

            seller_sku = m.group(0)
            key = (round(yc, 1), round(qx0, 1), seller_sku, qty)  # å»é‡é”®
            if key in seen:
                continue
            seen.add(key)

            raw_total += qty                  # æŒ‰è¡Œè®¡æ•°ï¼ˆå¯¹è´¦å£å¾„ï¼‰
            expand_bundle(expanded, seller_sku, qty)  # å±•å¼€è®¡æ•°ï¼ˆæ˜ç»†ï¼‰

    return expanded, raw_total, pages_with_header

# ====== è·¯å¾„2ï¼šOrderID é”šç‚¹å…œåº•ï¼ˆè·³è¿‡å·²è¡¨å¤´è§£æçš„é¡µé¢ï¼›åŒé¡µå»é‡ï¼‰ ======
def parse_by_order_anchor(doc, pages_to_skip=None):
    if pages_to_skip is None:
        pages_to_skip = set()

    expanded = defaultdict(int)
    raw_total = 0

    for pi, page in enumerate(doc):
        if pi in pages_to_skip:
            continue

        words = [(x0,y0,x1,y1,_clean(t)) for (x0,y0,x1,y1,t,_,_,_) in page.get_text('words')]
        if not words:
            continue

        heights = [y1-y0 for _,y0,_,y1,_ in words]
        line_h  = (sum(heights)/len(heights)) if heights else 12
        band    = line_h * 3.0

        # ç²—ä¼° SKU åˆ—å·¦ç•Œï¼ˆæ²¡æœ‰è¡¨å¤´ä¹Ÿèƒ½è·‘ï¼‰
        sku_left_guess = min([x0 for x0,_,_,_,t in words if 'sku' in t.lower()], default=page.rect.width*0.2)

        anchors = [(x0,y0,x1,y1,t) for x0,y0,x1,y1,t in words if ORDER_ID.match(t)]
        seen = set()  # æœ¬é¡µå»é‡

        for ax0,ay0,ax1,ay1,_ in anchors:
            yc = (ay0+ay1)/2
            # æ‰¾â€œæœ€é å³â€çš„ 1â€“3 ä½æ•°å­—ä½œä¸º Qtyï¼ˆåœ¨é”šç‚¹å·¦ä¾§ã€åŒä¸€è¡Œå¸¦ï¼‰
            qty_cands = [(x0,int(t)) for x0,y0,_,y1,t in words
                         if (x0 < ax0) and QTY_NUM.match(t) and abs(((y0+y1)/2)-yc) <= band]
            if not qty_cands:
                continue
            qx0, qty = max(qty_cands, key=lambda k:k[0])

            tokens=[]
            for sx0,sy0,_,sy1,t in words:
                if sku_left_guess <= sx0 < qx0 and abs(((sy0+sy1)/2)-yc) <= band and ALNUM_HYPHEN.match(t):
                    tokens.append((sy0, sx0, t))
            if not tokens:
                continue

            tokens.sort(key=lambda k: (round(k[0],1), k[1]))
            cat = re.sub(r'\s+','', ''.join(t for _,_,t in tokens))
            m = SKU_FULL.search(cat)
            if not m:
                continue

            seller_sku = m.group(0)
            key = (round(yc, 1), round(qx0, 1), seller_sku, qty)
            if key in seen:
                continue
            seen.add(key)

            raw_total += qty
            expand_bundle(expanded, seller_sku, qty)

    return expanded, raw_total

# ========= ä¸»æµç¨‹ =========
if uploaded_file:
    raw = uploaded_file.read()
    doc = fitz.open(stream=raw, filetype="pdf")

    # è¯»å– Item quantityï¼ˆç”¨äºä¸æ‹£è´§å•å¯¹è´¦ï¼‰
    all_text = "".join(p.get_text() for p in doc)
    m_total = re.search(r"Item quantity[:ï¼š]?\s*(\d+)", all_text)
    expected_total = int(m_total.group(1)) if m_total else None

    # å…ˆç”¨è¡¨å¤´è§£æï¼Œå†ç”¨é”šç‚¹å…œåº•ï¼ˆä»…åœ¨â€œæ²¡æœ‰è¡¨å¤´çš„é¡µé¢â€ä¸Šè·‘ï¼‰
    exp1, raw1, pages_with_header = parse_by_headers(doc)
    exp2, raw2 = parse_by_order_anchor(doc, pages_to_skip=pages_with_header)

    # åˆå¹¶å±•å¼€è®¡æ•°ï¼šä»¥è¡¨å¤´ä¸ºä¸»ï¼Œå…œåº•åªè¡¥â€œè¡¨å¤´æ²¡æŠ“åˆ°â€çš„é”®
    sku_counts = exp1.copy()
    for k, v in exp2.items():
        if k not in sku_counts:
            sku_counts[k] = v

    # æŒ‰è¡Œå¯¹è´¦å£å¾„ï¼šä¼˜å…ˆè¡¨å¤´ç»“æœï¼Œå¦åˆ™ç”¨å…œåº•
    raw_total = raw1 if raw1 > 0 else raw2

    if sku_counts:
        # ===== æ˜ç»†ï¼ˆå±•å¼€åï¼‰ =====
        df = pd.DataFrame(list(sku_counts.items()), columns=["Seller SKU", "Qty"])
        df["SKU Prefix"]  = df["Seller SKU"].str.split("-").str[0]
        df["Size"]        = df["Seller SKU"].str.split("-").str[1]
        df["Product Name"]= df["SKU Prefix"].map(lambda x: updated_mapping.get(x, "â“æœªè¯†åˆ«"))
        df = df[["Product Name","Size","Seller SKU","Qty"]].sort_values(by=["Product Name","Size"])

        # A. å±•å¼€ä»¶æ•°ï¼ˆç»™æ‹£è´§æ˜ç»†/å‡ºåº“ç”¨ï¼‰
        pieces_total = int(df["Qty"].sum())
        st.subheader(f"ğŸ“¦ å®é™…æ‹£è´§æ€»æ•°é‡ï¼š{pieces_total}")

        # B. å¯¹è´¦å£å¾„ï¼ˆæŒ‰è¡Œï¼Œä¸æ‹£è´§å• Item quantity å¯¹é½ï¼‰
        if expected_total is not None:
            if raw_total == expected_total:
                st.success(f"ğŸ§¾ å¯¹è´¦å£å¾„ï¼ˆæŒ‰è¡Œï¼‰ï¼š{raw_total}  âœ… ä¸æ‹£è´§å•ä¸€è‡´")
            else:
                st.error(f"ğŸ§¾ å¯¹è´¦å£å¾„ï¼ˆæŒ‰è¡Œï¼‰ï¼š{raw_total}  âŒ ä¸æ‹£è´§å• {expected_total} ä¸ä¸€è‡´")
        else:
            st.warning("âš ï¸ æœªèƒ½è¯†åˆ«æ‹£è´§å•çš„ Item quantityï¼ˆå¯¹è´¦å£å¾„æ— æ³•æ¯”å¯¹ï¼‰")

        st.dataframe(df, use_container_width=True)

        # ä¸‹è½½ç»“æœï¼ˆä¿æŒä½ åŸæ¥çš„æ–‡ä»¶å/ç¼–ç ï¼‰
        csv = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“¥ ä¸‹è½½äº§å“æ˜ç»† CSV", data=csv, file_name="product_summary_named.csv", mime="text/csv")

        map_df  = pd.DataFrame(list(updated_mapping.items()), columns=["SKU å‰ç¼€","äº§å“åç§°"])
        map_csv = map_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“ ä¸‹è½½ SKU æ˜ å°„è¡¨ CSV", data=map_csv, file_name="sku_prefix_mapping.csv", mime="text/csv")
    else:
        st.error("æœªè¯†åˆ«åˆ°ä»»ä½• SKU è¡Œã€‚è¯·ç¡®è®¤ PDF ä¸ºå¯å¤åˆ¶æ–‡æœ¬æˆ–å‘æˆ‘æ ·ä¾‹åšä¸€æ¬¡é€‚é…ã€‚")
        with st.expander("è°ƒè¯•é¢„è§ˆï¼ˆå‰ 800 å­—ï¼‰"):
            st.text(all_text[:800])
