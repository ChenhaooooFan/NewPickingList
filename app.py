import streamlit as st
import pandas as pd
import re
import fitz
from collections import defaultdict

st.set_page_config(page_title="æ‹£è´§å•æ±‡æ€»å·¥å…·(Â´âˆ€ï½€)â™¡", layout="centered")
st.title("NailVesta æ‹£è´§å•æ±‡æ€»å·¥å…·ğŸ’—")
st.caption("æå– Seller SKU + æ•°é‡ï¼Œå¹¶æ ¹æ® SKU å‰ç¼€æ˜ å°„äº§å“åç§°ï¼ˆæ”¯æŒ 1â€“4 ä»¶ bundleï¼›ä¿®å¤æ¢è¡ŒæŠŠæœ€åä¸€ä½æ•°å­—æŠ˜è¡Œåˆ°ä¸‹ä¸€è¡Œçš„æƒ…å†µï¼‰")

uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šä¼ æ‹£è´§ PDF", type=["pdf"])

# âœ… æ˜ å°„ï¼šSKU å‰ç¼€ â†’ äº§å“åï¼ˆä¿ç•™ä½ çš„æ˜ å°„ï¼›æ­¤å¤„åªåˆ—å‡ºç¤ºä¾‹ï¼Œå¯æ›¿æ¢ä¸ºä½ çš„å®Œæ•´æ˜ å°„ï¼‰
sku_prefix_to_name = {
    "NDF001":"Tropic Paradise","NPX014":"Afterglow","NDX001":"Pinky Promise","NHF001":"Gothic Moon","NHX001":"Emerald Garden",
    "NLF001":"Divine Emblem","NLF002":"Athena's Glow","NLJ001":"Golden Pearl","NLJ002":"BAROQUE BLISS","NLJ003":"Rainbow Reef",
    "NLX001":"Mermaid's Whisper","NLX003":"Tropical Tide","NLX005":"Pure Grace","NOF001":"Royal Amber","NOF002":"Tiger Lily",
    "NOF003":"Peach Pop","NOF004":"Sunset Punch","NOF005":"Glacier Petal","NOJ001":"Island Bloom","NOJ002":"Floral Lemonade",
    "NOJ003":"Aurora Tide","NOX001":"Lava Latte","NPD001":"Leopard's Kiss","NPF001":"Angel's Grace","NPF002":"Sacred Radiance",
    "NPF003":"Golden Ivy","NPF005":"Auric Taurus","NPF006":"Cocoa Blossom","NPF007":"Bluebell Glow","NPF008":"Lavender Angel",
    "NPF009":"Vintage Bloom","NPF010":"Pastel Meadow","NPF011":"Cherry Cheetah","NPF012":"Rosey Tigress","NPJ001":"SCARLET QUEEN",
    "NPJ003":"Stellar Capricorn","NPJ004":"Midnight Violet","NPJ005":"Vintage Cherry","NPJ006":"Savanna Bloom","NPJ007":"Angel's Blush",
    "NPJ008":"Gothic Sky","NPJ009":"Violet Seashell","NPX001":"Royal Elegance","NPX002":"Angel's Ruby","NPX005":"Indigo Breeze",
    "NPX006":"Autumn Petal","NPX007":"Lavender Bliss","NPX008":"Dreamy Ballerina","NPX009":"Rose Eden","NPX010":"Blooming Meadow",
    "NPX011":"Safari Petal","NPX012":"Milky Ribbon","NPX013":"Champagne Wishes","NLX004":"Holiday Bunny","NPJ010":"Glossy Doll",
    "NPF013":"Opal Glaze","NOX002":"Cherry Kiss","NOJ004":"Peachy Coast","NYJ001":"Rosy Ribbon","NOF008":"Starlit Jungle",
    "NOF006":"Coral Sea","NOF009":"RosÃ© Angel","NPF014":"Arabian Nights","NOX003":"Caramel Nova","NPF016":"Golden Muse",
    "NPF017":"Ruby Bloom","NOF007":"Citrus Blush","NOJ005":"Ocean Whisper","NPF015":"RosÃ© Petal","NOF010":"Spring Moss",
    "NM001":"Mystery Set","NOF011":"Velvet Flame","NPJ011":"Bat Boo","NOX004":"Azure Muse","NPX016":"Silky Pearl",
    "NPX015":"Spooky Clown","NOX005":"Honey Daisy","NPJ012":"Gothic Mirage","NOX006":"Imperial Bloom","NPX017":"Rouge Letter",
    "NOF013":"Sakura Blush","NPF018":"Wild Berry","NOF012":"Rose Nocturne","NIX001":"Golden Maple","NOX007":"Stellar Whisper",
    "NOF014":"Desert Rose","NPF019":"Lunar Whisper","NOF015":"Mocha Grace","NOX009":"Moonlit Petal","NOX008":"Espresso Petals",
    "NPX018":"Ruby Ribbon"
}
updated_mapping = dict(sku_prefix_to_name)

# ---------- å°å·¥å…· ----------
SKU_BUNDLE = re.compile(r'((?:[A-Z]{3}\d{3}){1,4}-[SML])', re.DOTALL)  # 1â€“4ä»¶ bundleï¼ˆå…è®¸è·¨è¡Œ/ç©ºæ ¼ï¼‰
QTY_AFTER  = re.compile(r'\b([1-9]\d{0,2})\b')                          # SKU åçš„ 1â€“3ä½æ•°é‡

def normalize_text(t: str) -> str:
    t = t.replace("\u00ad","").replace("\u200b","").replace("\u00a0"," ")
    t = t.replace("â€“","-").replace("â€”","-")
    return t

def fix_orphan_digit_before_size(txt: str) -> str:
    """
    ä¿®å¤å½¢å¦‚ï¼š
        NPJ011NPX01\n5-M  â†’ NPJ011NPX015-M
    çš„æ¢è¡ŒæŠ˜æ–­ã€‚å³ï¼šæœ€åä¸€ä¸ªâ€œ3ä½æ•°å­—â€è¢«åˆ‡æˆâ€œå‰2ä½åœ¨ä¸Šä¸€è¡Œ + æœ€åä¸€ä½åœ¨ä¸‹ä¸€è¡Œï¼Œå†æ¥ -SIZEâ€ã€‚
    è¿™é‡Œåªä¿®å¤æœ€åä¸€æ®µçš„â€œ2ä½æ•°å­— + æ¢è¡Œ + 1ä½æ•°å­— + -[SML]â€çš„åœºæ™¯ã€‚
    """
    # è§£é‡Šï¼š
    #  - prefix: å‰é¢è‹¥å¹²ä¸ªå®Œæ•´ 6 ä½å— + æœ€åä¸€ä¸ª 3 ä½å—åªå‰©ä¸‹ 2 ä½ï¼ˆå¦‚ X01ï¼‰
    #  - d: ä¸‹ä¸€è¡Œçš„â€œ1ä½æ•°å­—â€ï¼ˆå¦‚ 5ï¼‰
    #  - size: S/M/L
    # å…è®¸ä¸­é—´å‡ºç°ç©ºæ ¼æˆ–æ¢è¡Œ
    pattern = re.compile(
        r'(?P<prefix>(?:[A-Z]{3}\d{3}){0,3}[A-Z]{3}\d{2})\s*[\r\n]+\s*(?P<d>\d)\s*-\s*(?P<size>[SML])'
    )
    def _join(m):
        return f"{m.group('prefix')}{m.group('d')}-{m.group('size')}"
    # è¿ç»­ä¿®å¤ç›´åˆ°ä¸å†åŒ¹é…ï¼ˆæŸäº›é¡µå¯èƒ½å¤šå¤„å‡ºç°ï¼‰
    prev = None
    cur = txt
    while prev != cur:
        prev = cur
        cur = pattern.sub(_join, cur)
    return cur

def expand_bundle(counter: dict, sku_with_size: str, qty: int):
    """
    å°† 1â€“4 ä»¶ bundle æ‹†æˆç‹¬ç«‹ SKU è®¡æ•°ã€‚
    ä¾‹å¦‚ï¼šNPJ011NPX015-M â†’ NPJ011-M, NPX015-M å„ +qty
    """
    s = re.sub(r'\s+', '', sku_with_size)
    if '-' not in s:
        counter[s] += qty
        return
    code, size = s.split('-', 1)
    if len(code) % 6 == 0 and 6 <= len(code) <= 24:
        parts = [code[i:i+6] for i in range(0, len(code), 6)]
        if all(re.fullmatch(r'[A-Z]{3}\d{3}', p) for p in parts):
            for p in parts:
                counter[f"{p}-{size}"] += qty
            return
    # å›é€€ï¼šéæ ‡å‡†å°±æŒ‰åŸæ ·è®°
    counter[s] += qty

# ---------- ä¸»é€»è¾‘ ----------
if uploaded_file:
    # è¯» PDF â†’ æ–‡æœ¬
    raw = uploaded_file.read()
    doc = fitz.open(stream=raw, filetype="pdf")
    text = ""
    for p in doc:
        text += p.get_text("text") + "\n"
    text = normalize_text(text)

    # å¯¹è´¦ç”¨ï¼šItem quantity
    m_total = re.search(r"Item\s+quantity[:ï¼š]?\s*(\d+)", text, re.I)
    expected_total = int(m_total.group(1)) if m_total else None

    # å…³é”®ä¿®å¤ï¼šæŠŠâ€œæœ€åä¸€ä½æ•°å­—æ¢è¡Œåˆ°ä¸‹ä¸€è¡Œâ€çš„ SKU æ‹¼å›å»
    text_fixed = fix_orphan_digit_before_size(text)

    # åŒ¹é…æ‰€æœ‰ SKUï¼ˆå…è®¸è·¨è¡Œï¼‰
    sku_counts = defaultdict(int)
    for m in SKU_BUNDLE.finditer(text_fixed):
        sku_raw = re.sub(r'\s+', '', m.group(1))  # å»æ‰ä»»ä½•ç©ºç™½/æ¢è¡Œ
        # æ‰¾ SKU ä¹‹åçš„ç¬¬ä¸€ä¸ª 1â€“3 ä½æ•°å­—å½“ä½œæ•°é‡ï¼ˆTikTok é€šå¸¸ç´§è·Ÿåœ¨å³ä¾§ï¼‰
        after = text_fixed[m.end(): m.end()+50]
        mq = QTY_AFTER.search(after)
        qty = int(mq.group(1)) if mq else 1

        expand_bundle(sku_counts, sku_raw, qty)

    # ç”Ÿæˆç»“æœ
    if sku_counts:
        df = pd.DataFrame(list(sku_counts.items()), columns=["Seller SKU", "Qty"])
        df["SKU Prefix"]   = df["Seller SKU"].str.split("-").str[0]
        df["Size"]         = df["Seller SKU"].str.split("-").str[1]
        df["Product Name"] = df["SKU Prefix"].map(lambda x: updated_mapping.get(x, "â“æœªè¯†åˆ«"))

        # å…è®¸æ‰‹åŠ¨è¡¥å…¨æœªè¯†åˆ«å‰ç¼€
        unknown = df[df["Product Name"].str.startswith("â“")]["SKU Prefix"].unique().tolist()
        if unknown:
            st.warning("âš ï¸ æœ‰æœªè¯†åˆ«çš„ SKU å‰ç¼€ï¼Œè¯·è¡¥å…¨ï¼š")
            for prefix in unknown:
                name_input = st.text_input(f"ğŸ”§ SKU å‰ç¼€ {prefix} çš„äº§å“åç§°ï¼š", key=f"fix_{prefix}")
                if name_input:
                    updated_mapping[prefix] = name_input
                    df.loc[df["SKU Prefix"] == prefix, "Product Name"] = name_input

        df = df[["Product Name", "Size", "Seller SKU", "Qty"]].sort_values(by=["Product Name","Size"])
        total_qty = int(df["Qty"].sum())

        st.subheader(f"ğŸ“¦ å®é™…æ‹£è´§æ€»æ•°é‡ï¼š{total_qty}")
        if expected_total is not None:
            if total_qty == expected_total:
                st.success(f"âœ… ä¸æ‹£è´§å•ä¸€è‡´ï¼ˆ{expected_total}ï¼‰")
            else:
                st.warning(f"âš ï¸ æ‹£è´§å•æ•°é‡ä¸º {expected_total}ï¼Œå®é™…è§£æä¸º {total_qty}ã€‚å¦‚ä»ä¸ä¸€è‡´ï¼Œå¯èƒ½è¿˜æœ‰å…¶ä»–éå¸¸è§„æ¢è¡Œã€‚")

        st.dataframe(df, use_container_width=True)

        # ä¸‹è½½ç»“æœ
        csv = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“¥ ä¸‹è½½äº§å“æ˜ç»† CSV", data=csv, file_name="product_summary_named.csv", mime="text/csv")

        map_df = pd.DataFrame(list(updated_mapping.items()), columns=["SKU å‰ç¼€","äº§å“åç§°"])
        map_csv = map_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“ ä¸‹è½½ SKU æ˜ å°„è¡¨ CSV", data=map_csv, file_name="sku_prefix_mapping.csv", mime="text/csv")

    else:
        st.error("æœªè¯†åˆ«åˆ°ä»»ä½• SKU è¡Œã€‚è¯·ç¡®è®¤ PDF ä¸ºå¯å¤åˆ¶æ–‡æœ¬ï¼Œæˆ–å‘æˆ‘æ ·ä¾‹åšä¸€æ¬¡ä¸“ç”¨é€‚é…ã€‚")
