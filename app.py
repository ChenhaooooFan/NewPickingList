import streamlit as st
import pandas as pd
import re
import fitz
from collections import defaultdict

st.set_page_config(page_title="æ‹£è´§å•æ±‡æ€»å·¥å…·", layout="centered")
st.title("ðŸ“¦ NailVesta æ‹£è´§å•æ±‡æ€»å·¥å…·")
st.caption("æå– Seller SKU + æ•°é‡ï¼Œå¹¶æ ¹æ® SKU å‰ç¼€æ˜ å°„äº§å“åç§°")

uploaded_file = st.file_uploader("ðŸ“¤ ä¸Šä¼ æ‹£è´§ PDF", type=["pdf"])

# âœ… æ˜ å°„ï¼šSKU å‰ç¼€ â†’ äº§å“å
sku_prefix_to_name = {
    "NDF001": "Tropic Paradise",
    "NPX014": "Afterglow",
    "NDX001": "Pinky Promise",
    "NHF001": "Gothic Moon",
    "NHX001": "Emerald Garden",
    "NLF001": "Divine Emblem",
    "NLF002": "Athena's Glow",
    "NLJ001": "Golden Pearl",
    "NLJ002": "BAROQUE BLISS",
    "NLJ003": "Rainbow Reef",
    "NLX001": "Mermaid's Whisper",
    "NLX003": "Tropical Tide",
    "NLX005": "Pure Grace",
    "NOF001": "Royal Amber",
    "NOF002": "Tiger Lily",
    "NOF003": "Peach Pop",
    "NOF004": "Sunset Punch",
    "NOF005": "Glacier Petal",
    "NOJ001": "Island Bloom",
    "NOJ002": "Floral Lemonade",
    "NOJ003": "Aurora Tide",
    "NOX001": "Lava Latte",
    "NPD001": "Leopard's Kiss",
    "NPF001": "Angel's Grace",
    "NPF002": "Sacred Radiance",
    "NPF003": "Golden Ivy",
    "NPF005": "Auric Taurus",
    "NPF006": "Cocoa Blossom",
    "NPF007": "Bluebell Glow",
    "NPF008": "Lavender Angel",
    "NPF009": "Vintage Bloom",
    "NPF010": "Pastel Meadow",
    "NPF011": "Cherry Cheetah",
    "NPF012": "Rosey Tigress",
    "NPJ001": "SCARLET QUEEN",
    "NPJ003": "Stellar Capricorn",
    "NPJ004": "Midnight Violet",
    "NPJ005": "Vintage Cherry",
    "NPJ006": "Savanna Bloom",
    "NPJ007": "Angel's Blush",
    "NPJ008": "Gothic Sky",
    "NPJ009": "Violet Seashell",
    "NPX001": "Royal Elegance",
    "NPX002": "Angel's Ruby",
    "NPX005": "Indigo Breeze",
    "NPX006": "Autumn Petal",
    "NPX007": "Lavender Bliss",
    "NPX008": "Dreamy Ballerina",
    "NPX009": "Rose Eden",
    "NPX010": "Blooming Meadow",
    "NPX011": "Safari Petal",
    "NPX012": "Milky Ribbon",
    "NPX013": "Champagne Wishes",
    "NLX004": "Holiday Bunny",
    "NPJ010": "Glossy Doll",
    "NPF013": "Opal Glaze",
    "NOX002": "Cherry Kiss",
    "NOJ004": "Peachy Coast",
    "NYJ001": "Rosy Ribbon",
    "NOF008": "Starlit Jungle",
    "NOF006": "Coral Sea",
    "NOF009": "RosÃ© Angel",
    "NPF014": "Arabian Nights",
    "NOX003": "Caramel Nova",
    "NPF016": "Golden Muse",
    "NPF017": "Ruby Bloom",
    "NOF007": "Citrus Blush",
    "NOJ005": "Ocean Whisper",
    "NPF015": "RosÃ© Petal",
    "NOF010": "Spring Moss",
    "NM001": "Mystery Set",
    "NOF011": "Velvet Flame",
    "NPJ011": "Bat Boo",
    "NOX004": "Azure Muse",
    "NPX016": "Silky Pearl",
    "NPX015": "Spooky Clown",
    "NOX005": "Honey Daisy",
    "NPJ012": "Gothic Mirage",
    "NOX006": "Imperial Bloom",
    "NPX017": "Rouge Letter",
    "NOF013": "Sakura Blush",
    "NPF018": "Wild Berry",
    "NOF012": "Rose Nocturne",
    "NIX001": "Golden Maple",
    "NOX007": "Stellar Whisper",
    "NOF014": "Desert Rose",
    "NPF019": "Lunar Whisper",
    "NOF015": "Mocha Grace",
    "NOX009": "Moonlit Petal",
    "NOX008": "Espresso Petals",
    "NPX018": "Ruby Ribbon"
}

updated_mapping = dict(sku_prefix_to_name)

if uploaded_file:
    text = ""
    doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
    for page in doc:
        text += page.get_text()

    # â€”â€”â€” é¢„å¤„ç†ï¼šä¿®å¤è¢«æ‹†å¼€çš„ SKU & æ¸…ç†éšå½¢å­—ç¬¦ â€”â€”â€”
    # æŠŠè¢«ç¡¬æ¢è¡Œæ‹†å¼€çš„è¿žç»­å­—æ¯/æ•°å­—ç²˜åˆï¼Œä¾‹å¦‚ NPJ011NPX01\n5-M -> NPJ011NPX015-M
    text = re.sub(r'(?<=[A-Z0-9])\r?\n(?=[A-Z0-9])', '', text)
    # æ¸…ç†è½¯è¿žå­—ç¬¦ã€é›¶å®½ç©ºæ ¼
    text = text.replace('\u00ad', '').replace('\u200b', '')

    # è¯»å–æ‹£è´§å•æ€»æ•°ï¼ˆåŽŸé€»è¾‘ä¿æŒï¼‰
    total_quantity_match = re.search(r"Item quantity[:ï¼š]?\s*(\d+)", text)
    expected_total = int(total_quantity_match.group(1)) if total_quantity_match else None

    # â€”â€”â€” æ­£åˆ™ï¼šå…ˆä¸¥æ ¼åŒ¹é…ï¼ˆè¦æ±‚åŽé¢æœ‰ 9+ ä½æ¡ç ï¼‰ï¼Œè‹¥æ— ç»“æžœå†èµ°å®½æ¾åŒ¹é… â€”â€”â€”
    strict_pat = r"((?:[A-Z]{3}\s*\d\s*\d\s*\d){1,4}\s*-\s*[SML])\s+(\d+)\s+\d{9,}"
    loose_pat  = r"((?:[A-Z]{3}\s*\d\s*\d\s*\d){1,4}\s*-\s*[SML])\s+(\d+)(?:\s+\d{7,})?"

    matches = re.findall(strict_pat, text)
    if not matches:
        matches = re.findall(loose_pat, text)

    sku_counts = defaultdict(int)

    def expand_bundle_or_single(sku_with_size: str, qty: int):
        """
        1â€“4ä»¶ Bundle æ‹†åˆ†ï¼›ä¸æ»¡è¶³è§„åˆ™åˆ™åŽŸæ ·ç´¯è®¡ã€‚
        """
        sku_with_size = re.sub(r'\s+', '', sku_with_size)  # åŽ»æŽ‰å†…éƒ¨ç©ºç™½
        if "-" not in sku_with_size:
            sku_counts[sku_with_size] += qty
            return
        code, size = sku_with_size.split("-", 1)
        code = code.strip(); size = size.strip()

        if len(code) % 6 == 0 and 6 <= len(code) <= 24:
            parts = [code[i:i+6] for i in range(0, len(code), 6)]
            if all(re.fullmatch(r"[A-Z]{3}\d{3}", p) for p in parts):
                for p in parts:
                    sku_counts[f"{p}-{size}"] += qty
                return
        sku_counts[sku_with_size] += qty  # å›žé€€

    for raw_sku, qty in matches:
        expand_bundle_or_single(raw_sku, int(qty))

    if not sku_counts:
        st.error("æœªè¯†åˆ«åˆ°ä»»ä½• SKU è¡Œã€‚å¯èƒ½åŽŸå› ï¼š\n- PDF æ˜¯å›¾ç‰‡æ‰«æã€æ–‡å­—ä¸å¯é€‰\n- å•æ®é‡Œæ²¡æœ‰æ¡ç /é•¿æ•°å­—ï¼Œæˆ–æ ¼å¼ä¸ŽçŽ°æœ‰è§„åˆ™ä¸ä¸€è‡´\n- SKU/æ•°é‡è¢«éžå¸¸è§„æ¢è¡Œæ‹†åˆ†\n\nå»ºè®®ï¼šå°è¯•ä¸Šä¼ åŽŸå§‹å¯å¤åˆ¶æ–‡æœ¬çš„ PDFï¼Œæˆ–æŠŠè¯¥ PDF å‘æˆ‘åšä¸€æ¬¡é€‚é…ã€‚")
        with st.expander("è°ƒè¯•é¢„è§ˆï¼ˆå‰ 600 å­—ï¼‰"):
            st.text(text[:600])
        st.stop()

    # â€”â€”â€” åŽç»­ä¿æŒä¸å˜ â€”â€”â€”
    df = pd.DataFrame(list(sku_counts.items()), columns=["Seller SKU", "Qty"])
    df["SKU Prefix"] = df["Seller SKU"].apply(lambda x: x.split("-")[0])
    df["Size"] = df["Seller SKU"].apply(lambda x: x.split("-")[1])
    df["Product Name"] = df["SKU Prefix"].apply(lambda x: updated_mapping.get(x, "â“æœªè¯†åˆ«"))

    # ç”¨æˆ·æ‰‹åŠ¨è¡¥å…¨æœªçŸ¥å‰ç¼€
    unknown = df[df["Product Name"].str.startswith("â“")]["SKU Prefix"].unique().tolist()
    if unknown:
        st.warning("âš ï¸ æœ‰æœªè¯†åˆ«çš„ SKU å‰ç¼€ï¼Œè¯·è¡¥å…¨ï¼š")
        for prefix in unknown:
            name_input = st.text_input(f"ðŸ”§ SKU å‰ç¼€ {prefix} çš„äº§å“åç§°ï¼š", key=prefix)
            if name_input:
                updated_mapping[prefix] = name_input
                df.loc[df["SKU Prefix"] == prefix, "Product Name"] = name_input

    df = df[["Product Name", "Size", "Seller SKU", "Qty"]].sort_values(by=["Product Name", "Size"])

    total_qty = df["Qty"].sum()
    st.subheader(f"ðŸ“¦ å®žé™…æ‹£è´§æ€»æ•°é‡ï¼š{total_qty}")

    if expected_total:
        if total_qty == expected_total:
            st.success(f"âœ… ä¸Žæ‹£è´§å•ä¸€è‡´ï¼ï¼ˆ{expected_total}ï¼‰")
        else:
            st.error(f"âŒ æ•°é‡ä¸ä¸€è‡´ï¼æ‹£è´§å•ä¸º {expected_total}ï¼Œå®žé™…ä¸º {total_qty}")
    else:
        st.warning("âš ï¸ æœªèƒ½è¯†åˆ« Item quantity")

    st.dataframe(df)

    # ä¸‹è½½ç»“æžœ
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ðŸ“¥ ä¸‹è½½äº§å“æ˜Žç»† CSV", data=csv, file_name="product_summary_named.csv", mime="text/csv")

    map_df = pd.DataFrame(list(updated_mapping.items()), columns=["SKU å‰ç¼€", "äº§å“åç§°"])
    map_csv = map_df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ðŸ“ ä¸‹è½½ SKU æ˜ å°„è¡¨ CSV", data=map_csv, file_name="sku_prefix_mapping.csv", mime="text/csv")
