import streamlit as st
import pandas as pd
import re
import fitz
from collections import defaultdict

st.set_page_config(page_title="æ‹£è´§å•æ±‡æ€»å·¥å…·", layout="centered")
st.title("ğŸ“¦ NailVesta æ‹£è´§å•æ±‡æ€»å·¥å…·")
st.caption("æå– Seller SKU + æ•°é‡ï¼Œå¹¶æ ¹æ® SKU å‰ç¼€æ˜ å°„äº§å“åç§°")

uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šä¼ æ‹£è´§ PDF", type=["pdf"])

# âœ… æ˜ å°„ï¼šSKU å‰ç¼€ â†’ äº§å“åï¼ˆä¸å˜ï¼‰
sku_prefix_to_name = {
    "NDF001": "Tropic Paradise",
    "NPX014": "Afterglow",
    "NDX001": "Pinky Promise",
    "NHF001": "Gothic Moon",
    "NHX001": "Emerald Garden",
    "NLF001": "Divine Emblem",
    "NLF002": "Athena's Glow",
    "NLJ001": "Golden Pearl",
    "NLJ002": "BAROQUE BLISS",
    "NLJ003": "Rainbow Reef",
    "NLX001": "Mermaid's Whisper",
    "NLX003": "Tropical Tide",
    "NLX005": "Pure Grace",
    "NOF001": "Royal Amber",
    "NOF002": "Tiger Lily",
    "NOF003": "Peach Pop",
    "NOF004": "Sunset Punch",
    "NOF005": "Glacier Petal",
    "NOJ001": "Island Bloom",
    "NOJ002": "Floral Lemonade",
    "NOJ003": "Aurora Tide",
    "NOX001": "Lava Latte",
    "NPD001": "Leopard's Kiss",
    "NPF001": "Angel's Grace",
    "NPF002": "Sacred Radiance",
    "NPF003": "Golden Ivy",
    "NPF005": "Auric Taurus",
    "NPF006": "Cocoa Blossom",
    "NPF007": "Bluebell Glow",
    "NPF008": "Lavender Angel",
    "NPF009": "Vintage Bloom",
    "NPF010": "Pastel Meadow",
    "NPF011": "Cherry Cheetah",
    "NPF012": "Rosey Tigress",
    "NPJ001": "SCARLET QUEEN",
    "NPJ003": "Stellar Capricorn",
    "NPJ004": "Midnight Violet",
    "NPJ005": "Vintage Cherry",
    "NPJ006": "Savanna Bloom",
    "NPJ007": "Angel's Blush",
    "NPJ008": "Gothic Sky",
    "NPJ009": "Violet Seashell",
    "NPX001": "Royal Elegance",
    "NPX002": "Angel's Ruby",
    "NPX005": "Indigo Breeze",
    "NPX006": "Autumn Petal",
    "NPX007": "Lavender Bliss",
    "NPX008": "Dreamy Ballerina",
    "NPX009": "Rose Eden",
    "NPX010": "Blooming Meadow",
    "NPX011": "Safari Petal",
    "NPX012": "Milky Ribbon",
    "NPX013": "Champagne Wishes",
    "NLX004": "Holiday Bunny",
    "NPJ010": "Glossy Doll",
    "NPF013": "Opal Glaze",
    "NOX002": "Cherry Kiss",
    "NOJ004": "Peachy Coast",
    "NYJ001": "Rosy Ribbon",
    "NOF008": "Starlit Jungle",
    "NOF006": "Coral Sea",
    "NOF009": "RosÃ© Angel",
    "NPF014": "Arabian Nights",
    "NOX003": "Caramel Nova",
    "NPF016": "Golden Muse",
    "NPF017": "Ruby Bloom",
    "NOF007": "Citrus Blush",
    "NOJ005": "Ocean Whisper",
    "NPF015": "RosÃ© Petal",
    "NOF010": "Spring Moss",
    "NM001": "Mystery Set",
    "NOF011": "Velvet Flame",
    "NPJ011": "Bat Boo",
    "NOX004": "Azure Muse",
    "NPX016": "Silky Pearl",
    "NPX015": "Spooky Clown",
    "NOX005": "Honey Daisy",
    "NPJ012": "Gothic Mirage",
    "NOX006": "Imperial Bloom",
    "NPX017": "Rouge Letter",
    "NOF013": "Sakura Blush",
    "NPF018": "Wild Berry",
    "NOF012": "Rose Nocturne",
    "NIX001": "Golden Maple",
    "NOX007": "Stellar Whisper",
    "NOF014": "Desert Rose",
    "NPF019": "Lunar Whisper",
    "NOF015": "Mocha Grace",
    "NOX009": "Moonlit Petal",
    "NOX008": "Espresso Petals",
    "NPX018": "Ruby Ribbon"
}
updated_mapping = dict(sku_prefix_to_name)

# â€”â€” Bundle æ‹†åˆ†ï¼šæ”¯æŒ 1â€“4 ä»¶ï¼›ä¸åˆè§„åˆ™åŸæ ·ç´¯è®¡ â€”â€” #
def expand_bundle(counter: dict, sku_with_size: str, qty: int):
    s = re.sub(r'\s+', '', sku_with_size).replace('â€“', '-').replace('â€”', '-')
    if '-' not in s:
        counter[s] += qty; return
    code, size = s.split('-', 1)
    if len(code) % 6 == 0 and 6 <= len(code) <= 24:
        parts = [code[i:i+6] for i in range(0, len(code), 6)]
        if all(re.fullmatch(r'[A-Z]{3}\d{3}', p or '') for p in parts):
            for p in parts:
                counter[f'{p}-{size}'] += qty
            return
    counter[s] += qty

# â€”â€” æ ¸å¿ƒï¼šæŒ‰â€œåˆ—â€è§£æ â€”â€” #
def parse_table_like(doc) -> dict:
    sku_counts = defaultdict(int)

    for page in doc:
        words = page.get_text('words')  # (x0, y0, x1, y1, text, block, line, span)
        # è§„èŒƒåŒ–æ–‡æœ¬
        clean_words = []
        for x0, y0, x1, y1, t, b, ln, sp in words:
            t = (t.replace('\u00ad', '')   # è½¯è¿å­—ç¬¦
                   .replace('\u200b', '')  # é›¶å®½ç©ºæ ¼
                   .replace('\u00a0', ' ') # NBSP -> ç©ºæ ¼
                   .replace('â€“', '-')
                   .replace('â€”', '-'))
            if t.strip():
                clean_words.append((x0, y0, x1, y1, t, b, ln, sp))
        words = clean_words
        if not words:
            continue

        # 1) æ‰¾è¡¨å¤´æ‰€åœ¨è¡Œï¼šåŒ…å« "Seller" å’Œ "SKU"ï¼Œä»¥åŠ "Qty"
        header_candidates = {}
        for x0, y0, x1, y1, t, b, ln, sp in words:
            if t.lower() in ('seller', 'sku', 'seller sku', 'qty', 'quantity', 'order', 'order id'):
                header_candidates.setdefault((b, ln), []).append((x0, y0, x1, y1, t))
        header_key = None
        for key, items in header_candidates.items():
            labels = ' '.join([i[4].lower() for i in items])
            if ('seller' in labels and 'sku' in labels) and ('qty' in labels or 'quantity' in labels):
                header_key = key; break
        if header_key is None:
            # å…œåº•ï¼šç”¨æœ€é ä¸Šçš„ä¸€è¡Œ
            header_key = min({(b, ln) for _,_,_,_,_,b,ln,_ in words}, key=lambda k: k[1])

        # 2) è®¡ç®—å„åˆ— x èŒƒå›´ï¼šæ ¹æ®è¿™ä¸€è¡Œçš„å„æ ‡é¢˜ä½ç½®æ¨æ–­
        header_items = sorted([i for i in header_candidates.get(header_key, [])], key=lambda t: t[0])
        # å¦‚æœèƒ½æ‹¿åˆ°æ˜ç¡®çš„ Seller SKU å’Œ Qty çš„ x0
        xs = [i[0] for i in header_items]
        texts = [i[4].lower() for i in header_items]
        col_x = {}
        for x, txt in zip(xs, texts):
            if 'seller' in txt and 'sku' in txt:
                col_x['seller_sku'] = x
            if 'qty' in txt or 'quantity' in txt:
                col_x['qty'] = x

        # ä¸‡ä¸€æ²¡æŠ“åˆ°ï¼Œç”¨å¯å‘å¼ï¼šåœ¨é¡µé¢ä¸Šæ‰¾åŒ…å« "Seller" çš„è¯çš„ x0 ä½œä¸º Seller SKU åˆ—
        if 'seller_sku' not in col_x:
            ss = [x0 for x0,_,_,_,t,_,_,_ in words if t.lower() == 'seller']
            if ss: col_x['seller_sku'] = min(ss)
        if 'qty' not in col_x:
            qs = [x0 for x0,_,_,_,t,_,_,_ in words if t.lower() in ('qty','quantity')]
            if qs: col_x['qty'] = min(qs)

        if 'seller_sku' not in col_x or 'qty' not in col_x:
            # å¦‚æœåˆ—å¤´éƒ½æ‰¾ä¸åˆ°ï¼Œå°±ç›´æ¥æ”¾å¼ƒè¿™ä¸€é¡µï¼ˆé€šå¸¸ä¸ä¼šå‘ç”Ÿï¼‰
            continue

        # ç”¨æ ‡é¢˜çš„ x0 æ’åºå¾—åˆ°å„åˆ—è¾¹ç•Œï¼ˆä¸­ç‚¹å½“ä½œåˆ†ç•Œï¼‰
        header_positions = sorted([(col_x['seller_sku'], 'seller_sku'), (col_x['qty'], 'qty')], key=lambda x: x[0])
        # ä¼°ç®— seller_sku åˆ—èŒƒå›´ï¼šä»å®ƒçš„ x åˆ°ä¸‹ä¸€ä¸ªåˆ—çš„ä¸­ç‚¹
        page_width = page.rect.width
        def col_range(name):
            idx = [i for i,(_,n) in enumerate(header_positions) if n==name][0]
            left = header_positions[idx][0] - 5
            right = (header_positions[idx+1][0] - 5) if idx+1 < len(header_positions) else page_width
            return left, right
        sku_xmin, sku_xmax = col_range('seller_sku')
        qty_xmin, qty_xmax = col_range('qty')

        # 3) ä»¥â€œæ•°é‡è¯â€ä¸ºé”šç‚¹ï¼šåœ¨åŒä¸€è¡Œé™„è¿‘èšåˆè¯¥åˆ—çš„ Seller SKU å•å…ƒæ ¼ï¼ˆå¯è·¨ä¸¤è¡Œï¼‰
        #   - å…ˆä¼°è®¡ä¸€è¡Œé«˜åº¦
        heights = [y1 - y0 for _,y0,_,y1,_,_,_,_ in words]
        line_h = (sum(heights)/len(heights)) if heights else 10
        #   - æ‰¾æ‰€æœ‰ qty çº¯æ•°å­—è¯
        qty_words = []
        for x0,y0,x1,y1,t,b,ln,sp in words:
            if qty_xmin <= x0 <= qty_xmax and re.fullmatch(r'\d+', t.replace(',', '')):
                qty_words.append((x0,y0,x1,y1,int(t.replace(',',''))))
        #   - å¯¹æ¯ä¸ª qtyï¼Œå»åŒä¸€æ°´å¹³é™„è¿‘çš„ seller_sku åˆ—èšåˆæ‰€æœ‰è¯å¹¶æ‹¼æ¥
        for x0,y0,x1,y1,qty in qty_words:
            yc = (y0 + y1)/2
            sku_parts = []
            for sx0,sy0,sx1,sy1,t,b,ln,sp in words:
                if sku_xmin <= sx0 <= sku_xmax:
                    sc = (sy0 + sy1)/2
                    if abs(sc - yc) <= line_h * 1.2:  # å®¹å¿æ¢è¡Œçš„åŒä¸€â€œè¡Œå—â€
                        sku_parts.append((sx0, t))
            sku_parts = [t for _,t in sorted(sku_parts, key=lambda k: k[0])]
            if not sku_parts:
                continue
            sku_cell = ''.join(sku_parts)              # ç›´æ¥æ‹¼æ¥ï¼Œå¤„ç† NPJ011NPX01 + 5-M
            sku_cell = re.sub(r'\s+', '', sku_cell)
            # åªæ¥å—å½¢å¦‚ (ABC123){1,4}-[SML] çš„å•å…ƒæ ¼
            if re.fullmatch(r'(?:[A-Z]{3}\d{3}){1,4}-[A-Z]', sku_cell):
                expand_bundle(sku_counts, sku_cell, qty)

    return sku_counts

if uploaded_file:
    # æ‰“å¼€ PDF
    doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")

    # è¯»å–æ‹£è´§å•æ€»æ•°ï¼ˆä¿æŒä½ çš„åŸé€»è¾‘ï¼‰
    all_text = ""
    for p in doc:
        all_text += p.get_text()
    m = re.search(r"Item quantity[:ï¼š]?\s*(\d+)", all_text)
    expected_total = int(m.group(1)) if m else None

    # è¡¨æ ¼ç‰ˆè§£æ
    sku_counts = parse_table_like(doc)

    if not sku_counts:
        st.error("æœªè¯†åˆ«åˆ°ä»»ä½• SKU è¡Œï¼ˆè¡¨æ ¼åˆ—è§£æä¹Ÿæœªå‘½ä¸­ï¼‰ã€‚è¯·æŠŠæ ·ä¾‹ PDF å‘æˆ‘åšä¸€æ¬¡ä¸“ç”¨é€‚é…ï¼Œæˆ–å¯¼å‡ºä¸ºå¯å¤åˆ¶æ–‡æœ¬çš„ PDFã€‚")
        with st.expander("è°ƒè¯•é¢„è§ˆï¼ˆå‰ 800 å­—ï¼‰"):
            st.text(all_text[:800])
        st.stop()

    # â€”â€” åç»­ä¸åŸç‰ˆä¿æŒä¸€è‡´ â€”â€” #
    df = pd.DataFrame(list(sku_counts.items()), columns=["Seller SKU", "Qty"])
    df["SKU Prefix"] = df["Seller SKU"].apply(lambda x: x.split("-")[0])
    df["Size"] = df["Seller SKU"].apply(lambda x: x.split("-")[1])
    df["Product Name"] = df["SKU Prefix"].apply(lambda x: updated_mapping.get(x, "â“æœªè¯†åˆ«"))

    # æœªè¯†åˆ«å‰ç¼€å¯æ‰‹åŠ¨è¡¥å……ï¼ˆä¸å˜ï¼‰
    unknown = df[df["Product Name"].str.startswith("â“")]["SKU Prefix"].unique().tolist()
    if unknown:
        st.warning("âš ï¸ æœ‰æœªè¯†åˆ«çš„ SKU å‰ç¼€ï¼Œè¯·è¡¥å…¨ï¼š")
        for prefix in unknown:
            name_input = st.text_input(f"ğŸ”§ SKU å‰ç¼€ {prefix} çš„äº§å“åç§°ï¼š", key=prefix)
            if name_input:
                updated_mapping[prefix] = name_input
                df.loc[df["SKU Prefix"] == prefix, "Product Name"] = name_input

    # åˆ—é¡ºåºä¸æ’åºï¼ˆä¸å˜ï¼‰
    df = df[["Product Name", "Size", "Seller SKU", "Qty"]].sort_values(by=["Product Name", "Size"])

    total_qty = df["Qty"].sum()
    st.subheader(f"ğŸ“¦ å®é™…æ‹£è´§æ€»æ•°é‡ï¼š{total_qty}")

    if expected_total:
        if total_qty == expected_total:
            st.success(f"âœ… ä¸æ‹£è´§å•ä¸€è‡´ï¼ï¼ˆ{expected_total}ï¼‰")
        else:
            st.error(f"âŒ æ•°é‡ä¸ä¸€è‡´ï¼æ‹£è´§å•ä¸º {expected_total}ï¼Œå®é™…ä¸º {total_qty}")
    else:
        st.warning("âš ï¸ æœªèƒ½è¯†åˆ« Item quantity")

    st.dataframe(df)

    # ä¸‹è½½ç»“æœï¼ˆæ–‡ä»¶åä¸ç¼–ç ä¸å˜ï¼‰
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ğŸ“¥ ä¸‹è½½äº§å“æ˜ç»† CSV", data=csv, file_name="product_summary_named.csv", mime="text/csv")

    map_df = pd.DataFrame(list(updated_mapping.items()), columns=["SKU å‰ç¼€", "äº§å“åç§°"])
    map_csv = map_df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ğŸ“ ä¸‹è½½ SKU æ˜ å°„è¡¨ CSV", data=map_csv, file_name="sku_prefix_mapping.csv", mime="text/csv")
