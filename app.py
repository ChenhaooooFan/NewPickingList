import streamlit as st
import pandas as pd
import re
import fitz
from collections import defaultdict

st.set_page_config(page_title="æ‹£è´§å•æ±‡æ€»å·¥å…·(Â´âˆ€ï½€)â™¡", layout="centered")
st.title("NailVesta æ‹£è´§å•æ±‡æ€»å·¥å…·ðŸ’—")
st.caption("æå– Seller SKU + æ•°é‡ï¼Œå¹¶æ ¹æ® SKU å‰ç¼€æ˜ å°„äº§å“åç§°ï¼ˆæ”¯æŒ bundle ä¸Ž Mystery å¯¹è´¦è§„åˆ™ï¼‰")

uploaded_file = st.file_uploader("ðŸ“¤ ä¸Šä¼ æ‹£è´§ PDF", type=["pdf"])

# âœ… æ˜ å°„è¡¨ï¼ˆä¿æŒä¸å˜ï¼‰
# è¯¥æ˜ å°„è¡¨ä¿æŒä¸å˜
sku_prefix_to_name = {
    "NDF001":"Tropic Paradise","NPX014":"Afterglow","NDX001":"Pinky Promise","NHF001":"Gothic Moon","NHX001":"Emerald Garden",
    "NLF001":"Divine Emblem","NLF002":"Athena's Glow","NLJ001":"Golden Pearl","NLJ002":"BAROQUE BLISS","NLJ003":"Rainbow Reef",
    "NLX001":"Mermaid's Whisper","NLX003":"Tropical Tide","NLX005":"Pure Grace","NOF001":"Royal Amber","NOF002":"Tiger Lily",
    "NOF003":"Peach Pop","NOF004":"Sunset Punch","NOF005":"Glacier Petal","NOJ001":"Island Bloom","NOJ002":"Floral Lemonade",
    "NOJ003":"Aurora Tide","NOX001":"Lava Latte","NPD001":"Leopard's Kiss","NPF001":"Angel's Grace","NPF002":"Sacred Radiance",
    "NPF003":"Golden Ivy","NPF005":"Auric Taurus","NPF006":"Cocoa Blossom","NPF007":"Bluebell Glow","NPF008":"Lavender Angel",
    "NPF009":"Vintage Bloom","NPF010":"Pastel Meadow","NPF011":"Cherry Cheetah","NPF012":"Rosey Tigress","NPJ001":"SCARLET QUEEN",
    "NPJ003":"Stellar Capricorn","NPJ004":"Midnight Violet","NPJ005":"Vintage Cherry","NPJ006":"Savanna Bloom","NPJ007":"Angel's Blush",
    "NPJ008":"Gothic Sky","NPJ009":"Violet Seashell","NPX001":"Royal Elegance","NPX002":"Angel's Ruby","NPX005":"Indigo Breeze",
    "NPX006":"Autumn Petal","NPX007":"Lavender Bliss","NPX008":"Dreamy Ballerina","NPX009":"Rose Eden","NPX010":"Blooming Meadow",
    "NPX011":"Safari Petal","NPX012":"Milky Ribbon","NPX013":"Champagne Wishes","NLX004":"Holiday Bunny","NPJ010":"Glossy Doll",
    "NPF013":"Opal Glaze","NOX002":"Cherry Kiss","NOJ004":"Peachy Coast","NYJ001":"Rosy Ribbon","NOF008":"Starlit Jungle",
    "NOF006":"Coral Sea","NOF009":"RosÃ© Angel","NPF014":"Arabian Nights","NOX003":"Caramel Nova","NPF016":"Golden Muse",
    "NPF017":"Ruby Bloom","NOF007":"Citrus Blush","NOJ005":"Ocean Whisper","NPF015":"RosÃ© Petal","NOF010":"Spring Moss",
    "NM001":"Mystery Set","NOF011":"Velvet Flame","NPJ011":"Bat Boo","NOX004":"Azure Muse","NPX016":"Silky Pearl",
    "NPX015":"Spooky Clown","NOX005":"Honey Daisy","NPJ012":"Gothic Mirage","NOX006":"Imperial Bloom","NPX017":"Rouge Letter",
    "NOF013":"Sakura Blush","NPF018":"Wild Berry","NOF012":"Rose Nocturne","NIX001":"Golden Maple","NOX007":"Stellar Whisper",
    "NOF014":"Desert Rose","NPF019":"Lunar Whisper","NOF015":"Mocha Grace","NOX009":"Moonlit Petal","NOX008":"Espresso Petals",
    "NPX018":"Ruby Ribbon","NPF020":"Amber Mist","NOJ006":"Toffee Muse","NOJ007":"Cherry Glaze","NOX011":"Opal Mirage",
    "NOF016":"Cinnamon Bloom","NOX010":"Twilight Muse","NPX020":"Peachy Glaze","NPX019":"Blossom Tart","NPJ013":"Velvet Cherry",
    "NOX012":"Harvest Glaze","NOJ008":"Crystal Whisper","NOF017":"Twinkle Bow","NPX021":"Twinkle Pine","NOF018":"Glacier Bloom",
    "NOJ010":"Ruby Christmas","NPX022":"Merry Charm","NPF022":"Holiday Sparkl","NOF020":"Garnet Muse","NOF019":"Twinkle Christmas",
    "NOJ011":"Snowy Comet","NOX013":"Christmas Village","NOJ009":"Reindeer Glow","NIX002":"Golden Orchid", "NPX021":"Twinkle Pine",
    "NOF018":"Glacier Bloom","NOJ010":"Ruby Christmas","NPX022":"Merry Charm", "NPJ014":"Snow Pixie","NPJ018":"Frost Ruby",
    "NPJ017":"Starlit Rift","NPF021":"Candy Cane","NPJ016":"Fairy Nectar","NPJ015":"Icy Viper","NOX014":"Taro Petal","NVT001":"Tool Kits",
    "NF001":"Free Giveaway","NIF001":"Lilac Veil","NIF002":"Gingerbread","NOX015":"Glitter Doll","NOJ012":"Winery Flame","NOF021":"Velvet Ribbon","NPX024":"Rose Wine","NPX023":"Rosy Promise","NMF001":"Cherry Crush"
}
updated_mapping = dict(sku_prefix_to_name)

# ðŸ†• æ–°æ¬¾æ˜ å°„è¡¨ï¼Œæ‰€æœ‰æ–°æ¬¾åŠ åˆ°è¿™ï¼Œæ ¼å¼ä¸ºï¼š"NOF018":"Glacier Bloom"
new_sku_prefix = {
    "NPJ014":"Snow Pixie","NPJ018":"Frost Ruby","NPJ017":"Starlit Rift","NPF021":"Candy Cane",
    "NPJ016":"Fairy Nectar","NPJ015":"Icy Viper","NOX014":"Taro Petal","NIF001":"Lilac Veil","NIF002":"Gingerbread","NOX015":"Glitter Doll","NOJ012":"Winery Flame","NOF021":"Velvet Ribbon"
}

# ---------- å°å·¥å…· ----------
# æ”¯æŒ NF001ï¼Œæ— å°ºç  bundle
SKU_BUNDLE = re.compile(r'((?:[A-Z]{3}\d{3}|NF001){1,4}-[SML])', re.DOTALL)
QTY_AFTER  = re.compile(r'\b([1-9]\d{0,2})\b')
ITEM_QTY_RE = re.compile(r"Item\s+quantity[:ï¼š]?\s*(\d+)", re.I)
NM_ONLY = re.compile(r'\bNF001\b')

def normalize_text(t: str) -> str:
    return t.replace("\u00ad","").replace("\u200b","").replace("\u00a0"," ").replace("â€“","-").replace("â€”","-")

def fix_orphan_digit_before_size(txt: str) -> str:
    pattern = re.compile(r'(?P<prefix>(?:[A-Z]{3}\d{3}|NM001){0,3}[A-Z]{3}\d{2})\s*[\r\n]+\s*(?P<d>\d)\s*-\s*(?P<size>[SML])')
    def _join(m): return f"{m.group('prefix')}{m.group('d')}-{m.group('size')}"
    prev, cur = None, txt
    while prev != cur:
        prev, cur = cur, pattern.sub(_join, cur)
    return cur

def parse_code_parts(code: str):
    parts, i, n = [], 0, len(code)
    while i < n:
        if code.startswith('NM001', i): 
            parts.append('NM001'); 
            i += 5; 
            continue
        seg = code[i:i+6]
        if re.fullmatch(r'[A-Z]{3}\d{3}', seg):
            parts.append(seg); 
            i += 6; 
            continue
        return None
    return parts if 1 <= len(parts) <= 4 else None

def expand_bundle(counter: dict, sku_with_size: str, qty: int):
    s = re.sub(r'\s+', '', sku_with_size)
    if '-' not in s:
        counter[s] += qty
        return 0, (qty if s == 'NF001' else 0)
    code, size = s.split('-', 1)
    parts = parse_code_parts(code)
    if parts:
        mystery_units = 0
        for p in parts:
            key = f"{p}-{size}"
            counter[key] += qty
            if p == 'NF001':
                mystery_units += qty
        extra = (len(parts) - 1) * qty
        return extra, mystery_units
    counter[s] += qty
    return 0, (qty if code == 'NF001' else 0)

# ---------- ä¸»é€»è¾‘ ----------
if uploaded_file:
    raw = uploaded_file.read()
    doc = fitz.open(stream=raw, filetype="pdf")
    text = "\n".join([p.get_text("text") for p in doc])
    text = normalize_text(text)

    # å¯¹è´¦åŽŸå§‹æ•°é‡
    m_total = ITEM_QTY_RE.search(text)
    expected_total = int(m_total.group(1)) if m_total else 0

    # ä¿®å¤æ¢è¡Œæ–­è£‚ SKU
    text_fixed = fix_orphan_digit_before_size(text)

    # æå– SKU æ•°é‡
    sku_counts = defaultdict(int)
    bundle_extra = 0
    mystery_units = 0

    # â€”â€” å«å°ºç éƒ¨åˆ† â€”â€”
    for m in SKU_BUNDLE.finditer(text_fixed):
        sku_raw = re.sub(r'\s+', '', m.group(1))
        after = text_fixed[m.end(): m.end()+50]
        mq = QTY_AFTER.search(after)
        qty = int(mq.group(1)) if mq else 1
        extra, myst = expand_bundle(sku_counts, sku_raw, qty)
        bundle_extra += extra
        mystery_units += myst

    # â€”â€” æ— å°ºç  NF001 â€”â€”
    for m in NM_ONLY.finditer(text_fixed):
        nxt = text_fixed[m.end(): m.end()+3]
        if '-' in nxt: 
            continue
        after = text_fixed[m.end(): m.end()+80]
        mq = QTY_AFTER.search(after)
        qty = int(mq.group(1)) if mq else 1
        sku_counts['NF001'] += qty
        mystery_units += qty

    # å®žé™…æå–
    total_qty = sum(sku_counts.values())
    expected_bundle = expected_total + bundle_extra
    expected_final = expected_bundle - mystery_units  # âœ… å¯¹è´¦è§„åˆ™ï¼šbundle + mystery æŠµæ‰£

    # è¡¨æ ¼è¾“å‡º
    if sku_counts:
        df = pd.DataFrame(list(sku_counts.items()), columns=["Seller SKU", "Qty"])
        df["SKU Prefix"]   = df["Seller SKU"].str.split("-").str[0]
        df["Size"]         = df["Seller SKU"].str.split("-").str[1]
        df["Product Name"] = df["SKU Prefix"].map(lambda x: updated_mapping.get(x, "â“æœªè¯†åˆ«"))

        # ä¿æŒåŽŸæ¥çš„åˆ—é¡ºåºåŸºç¡€
        df = df[["Product Name", "Size", "Seller SKU", "Qty"]]

        # ðŸ†• æ–°æ¬¾ä¼˜å…ˆæŽ’åºï¼ˆæ–°æ¬¾æ˜ å°„è¡¨åœ¨ä¸Šï¼Œè€æ¬¾åœ¨ä¸‹ï¼‰
        is_new = df["Seller SKU"].str.split("-").str[0].isin(new_sku_prefix.keys())
        df = df.assign(_is_new=is_new).sort_values(
            by=["_is_new", "Product Name", "Size"],
            ascending=[False, True, True]
        ).drop(columns=["_is_new"])

        # ðŸ“Š å¯¹è´¦å±•ç¤º
        st.subheader("ðŸ“¦ å¯¹è´¦ç»“æžœ")
        st.markdown(f"""
        - PDF æ ‡æ³¨æ•°é‡ï¼ˆItem quantityï¼‰: **{expected_total}**  
        - bundle é¢å¤–ä»¶æ•°ï¼ˆ+ï¼‰: **{bundle_extra}**  
        - Mystery(NF001) ä»¶æ•°ï¼ˆâˆ’ï¼‰: **{mystery_units}**  
        - è°ƒæ•´åŽæœŸæœ›å€¼ï¼ˆbundleâˆ’Mysteryï¼‰: **{expected_final}**  
        - å®žé™…æå–æ•°é‡: **{total_qty}**
        """)

        if expected_total == 0:
            st.warning("âš ï¸ æœªè¯†åˆ«åˆ° Item quantityã€‚")
        elif total_qty == expected_total:
            st.success(f"âœ… ä¸ŽåŽŸå§‹ PDF æ•°é‡ä¸€è‡´ï¼ˆ{expected_total}ï¼‰")
        elif total_qty == expected_bundle:
            st.info(f"â„¹ï¸ ä¸ŽåŽŸå§‹ä¸ç¬¦ï¼Œä½†è€ƒè™‘ bundle åŽç›¸ç¬¦ï¼ˆå·® {total_qty - expected_total}ï¼‰")
        elif total_qty == expected_final:
            st.success(f"âœ… ä¸Ž PDF æ•°é‡ä¸ç¬¦ï¼Œä½†è€ƒè™‘ bundle ä¸Ž Mystery æŠµæ‰£åŽç›¸ç¬¦ï¼ˆæœŸæœ› {expected_final}ï¼‰")
        else:
            st.error(f"âŒ ä¸ä¸€è‡´ï¼šPDF {expected_total} â†’ è°ƒæ•´åŽ {expected_final}ï¼Œå®žé™… {total_qty}")

        # ðŸŒ¸ æ–°æ¬¾æ·¡ç²‰è‰²é«˜äº®
        def highlight_newrow(row):
            prefix = str(row["Seller SKU"]).split("-")[0]
            if prefix in new_sku_prefix:
                return ['background-color: #ffe4ec'] * len(row)
            return [''] * len(row)

        df_styled = df.style.apply(highlight_newrow, axis=1)

        # æ˜Žç»†è¡¨
        st.dataframe(df_styled, use_container_width=True)

        # ä¸‹è½½ï¼ˆä»ç”¨åŽŸå§‹ dfï¼Œæ— é¢œè‰²ï¼‰
        csv = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ðŸ“¥ ä¸‹è½½äº§å“æ˜Žç»† CSV", data=csv, file_name="product_summary_named.csv", mime="text/csv")

    else:
        st.error("æœªè¯†åˆ«åˆ°ä»»ä½• SKUã€‚è¯·ç¡®è®¤ PDF ä¸ºå¯å¤åˆ¶æ–‡æœ¬ã€‚")
