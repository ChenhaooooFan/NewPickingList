import streamlit as st
import pandas as pd
import re
import fitz
from collections import defaultdict

st.set_page_config(page_title="æ‹£è´§å•æ±‡æ€»å·¥å…·", layout="centered")
st.title("ğŸ“¦ NailVesta æ‹£è´§å•æ±‡æ€»å·¥å…·")
st.caption("æå– Seller SKU + æ•°é‡ï¼Œå¹¶æ ¹æ® SKU å‰ç¼€æ˜ å°„äº§å“åç§°")

uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šä¼ æ‹£è´§ PDF", type=["pdf"])

# âœ… æ˜ å°„ï¼šSKU å‰ç¼€ â†’ äº§å“åï¼ˆä¿æŒä¸å˜ï¼‰
sku_prefix_to_name = {
    "NDF001": "Tropic Paradise", "NPX014": "Afterglow", "NDX001": "Pinky Promise",
    "NHF001": "Gothic Moon", "NHX001": "Emerald Garden", "NLF001": "Divine Emblem",
    "NLF002": "Athena's Glow", "NLJ001": "Golden Pearl", "NLJ002": "BAROQUE BLISS",
    "NLJ003": "Rainbow Reef", "NLX001": "Mermaid's Whisper", "NLX003": "Tropical Tide",
    "NLX005": "Pure Grace", "NOF001": "Royal Amber", "NOF002": "Tiger Lily",
    "NOF003": "Peach Pop", "NOF004": "Sunset Punch", "NOF005": "Glacier Petal",
    "NOJ001": "Island Bloom", "NOJ002": "Floral Lemonade", "NOJ003": "Aurora Tide",
    "NOX001": "Lava Latte", "NPD001": "Leopard's Kiss", "NPF001": "Angel's Grace",
    "NPF002": "Sacred Radiance", "NPF003": "Golden Ivy", "NPF005": "Auric Taurus",
    "NPF006": "Cocoa Blossom", "NPF007": "Bluebell Glow", "NPF008": "Lavender Angel",
    "NPF009": "Vintage Bloom", "NPF010": "Pastel Meadow", "NPF011": "Cherry Cheetah",
    "NPF012": "Rosey Tigress", "NPJ001": "SCARLET QUEEN", "NPJ003": "Stellar Capricorn",
    "NPJ004": "Midnight Violet", "NPJ005": "Vintage Cherry", "NPJ006": "Savanna Bloom",
    "NPJ007": "Angel's Blush", "NPJ008": "Gothic Sky", "NPJ009": "Violet Seashell",
    "NPX001": "Royal Elegance", "NPX002": "Angel's Ruby", "NPX005": "Indigo Breeze",
    "NPX006": "Autumn Petal", "NPX007": "Lavender Bliss", "NPX008": "Dreamy Ballerina",
    "NPX009": "Rose Eden", "NPX010": "Blooming Meadow", "NPX011": "Safari Petal",
    "NPX012": "Milky Ribbon", "NPX013": "Champagne Wishes", "NLX004": "Holiday Bunny",
    "NPJ010": "Glossy Doll", "NPF013": "Opal Glaze", "NOX002": "Cherry Kiss",
    "NOJ004": "Peachy Coast", "NYJ001": "Rosy Ribbon", "NOF008": "Starlit Jungle",
    "NOF006": "Coral Sea", "NOF009": "RosÃ© Angel", "NPF014": "Arabian Nights",
    "NOX003": "Caramel Nova", "NPF016": "Golden Muse", "NPF017": "Ruby Bloom",
    "NOF007": "Citrus Blush", "NOJ005": "Ocean Whisper", "NPF015": "RosÃ© Petal",
    "NOF010": "Spring Moss", "NM001": "Mystery Set", "NOF011": "Velvet Flame",
    "NPJ011": "Bat Boo", "NOX004": "Azure Muse", "NPX016": "Silky Pearl",
    "NPX015": "Spooky Clown", "NOX005": "Honey Daisy", "NPJ012": "Gothic Mirage",
    "NOX006": "Imperial Bloom", "NPX017": "Rouge Letter", "NOF013": "Sakura Blush",
    "NPF018": "Wild Berry", "NOF012": "Rose Nocturne", "NIX001": "Golden Maple",
    "NOX007": "Stellar Whisper", "NOF014": "Desert Rose", "NPF019": "Lunar Whisper",
    "NOF015": "Mocha Grace", "NOX009": "Moonlit Petal", "NOX008": "Espresso Petals",
    "NPX018": "Ruby Ribbon"
}
updated_mapping = dict(sku_prefix_to_name)

# â€”â€” å°å·¥å…· â€”â€” #
def _clean(t: str) -> str:
    return (t.replace('\u00ad','')   # è½¯è¿å­—ç¬¦
             .replace('\u200b','')  # é›¶å®½ç©ºæ ¼
             .replace('\u00a0',' ') # NBSP
             .replace('â€“','-').replace('â€”','-'))

# 1â€“4 ä»¶ bundle æ‹†åˆ†
def expand_bundle(counter: dict, sku_with_size: str, qty: int):
    s = re.sub(r'\s+','', sku_with_size).replace('â€“','-').replace('â€”','-')
    if '-' not in s:
        counter[s] += qty; return
    code, size = s.split('-', 1)
    if len(code) % 6 == 0 and 6 <= len(code) <= 24:
        parts = [code[i:i+6] for i in range(0, len(code), 6)]
        if all(re.fullmatch(r'[A-Z]{3}\d{3}', p or '') for p in parts):
            for p in parts:
                counter[f'{p}-{size}'] += qty
            return
    counter[s] += qty  # å›é€€

# â€”â€” ç”¨ Order ID é”šç‚¹åæ¨æ•´è¡Œï¼ˆä¸“æ²»â€œSKU è¢«æ‹†æˆä¸¤è¡Œâ€çš„æƒ…å†µï¼‰ â€”â€” #
def parse_rows_by_anchor(doc) -> dict:
    out = defaultdict(int)
    for page in doc:
        words = [(x0,y0,x1,y1,_clean(t),b,ln,sp)
                 for (x0,y0,x1,y1,t,b,ln,sp) in page.get_text('words')
                 if _clean(t).strip()]
        if not words:
            continue

        # è¡Œé«˜ä¸è¡Œå¸¦å®¹å·®ï¼ˆæ”¾å®½åˆ° 2.5Ã—ï¼Œèƒ½è¦†ç›–å•å…ƒæ ¼å†…çš„æ¢è¡Œï¼‰
        heights = [y1-y0 for _,y0,_,y1,_,_,_,_ in words]
        line_h = (sum(heights)/len(heights)) if heights else 12
        band   = line_h * 2.5

        # æ‰¾åˆ°æ‰€æœ‰ Order IDï¼ˆâ‰¥9 ä½æ•°å­—ï¼‰ï¼Œä¸€è¡Œå°±ä¸€ä¸ª
        anchors = [(x0,y0,x1,y1,t) for x0,y0,x1,y1,t,_,_,_ in words
                   if re.fullmatch(r'\d{9,}', t.replace(',',''))]

        for ax0,ay0,ax1,ay1,_ in anchors:
            yc = (ay0+ay1)/2

            # 1) æ‰¾ Qtyï¼šåœ¨é”šç‚¹å·¦ä¾§ã€â€œåŒä¸€è¡Œå¸¦â€ã€å¹¶ä¸”å–â€œæœ€é å³â€çš„ 1â€“3 ä½æ•°å­—
            qty_cands = [(x0, int(t.replace(',',''))) for x0,y0,_,y1,t,_,_,_ in words
                         if (x0 < ax0) and re.fullmatch(r'\d{1,3}', t.replace(',',''))
                         and abs(((y0+y1)/2) - yc) <= band]
            if not qty_cands:
                continue
            qx0, qty = max(qty_cands, key=lambda k: k[0])

            # 2) åœ¨ Qty å·¦ä¾§ï¼Œæ”¶é›†â€œç–‘ä¼¼ Seller SKUâ€çš„è¯ï¼š
            #    åªä¿ç•™ç”± å¤§å†™å­—æ¯/æ•°å­—/è¿å­—ç¬¦ ç»„æˆçš„ tokenï¼ˆèƒ½æ‹¿åˆ°â€œNPJ011NPX01â€å’Œâ€œ5-Mâ€ï¼‰
            sku_tokens = []
            for sx0,sy0,_,sy1,t,_,_,_ in words:
                if sx0 < qx0 and abs(((sy0+sy1)/2) - yc) <= band:
                    if re.fullmatch(r'[A-Z0-9-]+', t):
                        sku_tokens.append((sy0, sx0, t))
            if not sku_tokens:
                continue

            # 3) å…ˆçºµåæ¨ªï¼Œæ‹¼æˆæ•´å—ï¼›å†ç”¨æ­£åˆ™æŠ½å‡ºç›®æ ‡ç‰‡æ®µ
            sku_tokens.sort(key=lambda k: (round(k[0], 1), k[1]))
            candidate = re.sub(r'\s+', '', ''.join(t for _,_,t in sku_tokens))
            m = re.search(r'(?:[A-Z]{3}\d{3}){1,4}-[A-Z]', candidate)
            if not m:
                continue
            seller_sku = m.group(0)
            expand_bundle(out, seller_sku, qty)
    return out

if uploaded_file:
    # è¯» PDF
    data = uploaded_file.read()
    doc = fitz.open(stream=data, filetype="pdf")

    # æå–å…¨æ–‡ç”¨äº â€œItem quantityâ€ æ ¡éªŒï¼ˆä¿ç•™ä½ åŸæ¥çš„è¡Œä¸ºï¼‰
    all_text = "".join(p.get_text() for p in doc)
    m_total = re.search(r"Item quantity[:ï¼š]?\s*(\d+)", all_text)
    expected_total = int(m_total.group(1)) if m_total else None

    # â€”â€” åªç”¨â€œé”šç‚¹æ³•â€åšè§£æï¼ˆæ›´ç¨³ï¼Œèƒ½æŠ“åˆ°è·¨è¡Œçš„ Bundleï¼‰ â€”â€” #
    sku_counts = parse_rows_by_anchor(doc)

    if sku_counts:
        df = pd.DataFrame(list(sku_counts.items()), columns=["Seller SKU", "Qty"])
        df["SKU Prefix"] = df["Seller SKU"].apply(lambda x: x.split("-")[0])
        df["Size"]       = df["Seller SKU"].apply(lambda x: x.split("-")[1])
        df["Product Name"] = df["SKU Prefix"].apply(lambda x: updated_mapping.get(x, "â“æœªè¯†åˆ«"))

        # æœªè¯†åˆ«å‰ç¼€å¯æ‰‹åŠ¨è¡¥å…¨ï¼ˆä¿æŒä½ çš„äº¤äº’ï¼‰
        unknown = df[df["Product Name"].str.startswith("â“")]["SKU Prefix"].unique().tolist()
        if unknown:
            st.warning("âš ï¸ æœ‰æœªè¯†åˆ«çš„ SKU å‰ç¼€ï¼Œè¯·è¡¥å…¨ï¼š")
            for prefix in unknown:
                name_input = st.text_input(f"ğŸ”§ SKU å‰ç¼€ {prefix} çš„äº§å“åç§°ï¼š", key=prefix)
                if name_input:
                    updated_mapping[prefix] = name_input
                    df.loc[df["SKU Prefix"] == prefix, "Product Name"] = name_input

        # åˆ—é¡ºåºä¸ä¸‹è½½ï¼ˆå®Œå…¨ä¸å˜ï¼‰
        df = df[["Product Name", "Size", "Seller SKU", "Qty"]].sort_values(by=["Product Name", "Size"])

        total_qty = int(df["Qty"].sum())
        st.subheader(f"ğŸ“¦ å®é™…æ‹£è´§æ€»æ•°é‡ï¼š{total_qty}")

        if expected_total is not None:
            if total_qty == expected_total:
                st.success(f"âœ… ä¸æ‹£è´§å•ä¸€è‡´ï¼ï¼ˆ{expected_total}ï¼‰")
            else:
                st.error(f"âŒ æ•°é‡ä¸ä¸€è‡´ï¼æ‹£è´§å•ä¸º {expected_total}ï¼Œå®é™…ä¸º {total_qty}")
        else:
            st.warning("âš ï¸ æœªèƒ½è¯†åˆ« Item quantity")

        st.dataframe(df)

        # ä¸‹è½½ç»“æœï¼ˆæ–‡ä»¶åä¸ç¼–ç ä¿æŒä¸å˜ï¼‰
        csv = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“¥ ä¸‹è½½äº§å“æ˜ç»† CSV", data=csv, file_name="product_summary_named.csv", mime="text/csv")

        map_df  = pd.DataFrame(list(updated_mapping.items()), columns=["SKU å‰ç¼€", "äº§å“åç§°"])
        map_csv = map_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“ ä¸‹è½½ SKU æ˜ å°„è¡¨ CSV", data=map_csv, file_name="sku_prefix_mapping.csv", mime="text/csv")
    else:
        st.error("æœªè¯†åˆ«åˆ°ä»»ä½• SKU è¡Œï¼ˆé”šç‚¹æ³•ä»æœªå‘½ä¸­ï¼‰ã€‚è¯·ç¡®è®¤ PDF ä¸ºå¯å¤åˆ¶æ–‡æœ¬ï¼Œæˆ–æŠŠæ ·ä¾‹å‘æˆ‘åšä¸€æ¬¡ä¸“ç”¨é€‚é…ã€‚")
        with st.expander("è°ƒè¯•é¢„è§ˆï¼ˆå‰ 800 å­—ï¼‰"):
            st.text(all_text[:800])
